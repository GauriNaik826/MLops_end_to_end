# ğŸš€ End-to-End MLops Project

## ğŸ“Œ Overview

This project is an **end-to-end MLops pipeline** for sentiment analysis that takes a machine learning model from **data ingestion â†’ preprocessing â†’ training â†’ evaluation â†’ tracking â†’ deployment**.
It integrates **MLflow, DVC, S3, Docker, Flask, GitHub Actions (CI/CD)** and experiment tracking with **DagsHub**.

---

## ğŸ—ï¸ Architecture

```
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚   Raw Data  â”‚
                â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                 Data Ingestion
                       â”‚
                 Preprocessing
                       â”‚
                  Model Training
                       â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                           â”‚
   MLflow Tracking             DVC + S3 Storage
         â”‚                           â”‚
   Metrics, Params              Data & Model Versioning
         â”‚
   Model Registry (DagsHub MLflow)
         â”‚
    Flask App (Serving)
         â”‚
   Dockerized Application â†’ CI/CD â†’ (AWS/EKS deployment)
```

---

## âš™ï¸ Features Implemented

âœ… **Experiment Tracking** with MLflow on **DagsHub**
âœ… **Pipeline Automation** with DVC
âœ… **Data Versioning** using DVC + AWS S3
âœ… **Unit Tests** for both ML pipeline and Flask API
âœ… **CI/CD** with GitHub Actions (automated pipeline + tests + model promotion)
âœ… **Containerization** of Flask App using Docker
âœ… **Environment Management** with `.env` file and GitHub Secrets
âœ… **Monitoring** setup using Prometheus & Grafana (to be expanded for cloud deployment)

---

## ğŸ“‚ Project Structure

```
MLops_end_to_end/
â”‚â”€â”€ data/                # Raw & processed data (DVC tracked)
â”‚â”€â”€ models/              # Saved models & vectorizers
â”‚â”€â”€ notebooks/           # Jupyter experiments
â”‚â”€â”€ reports/             # Metrics, experiment info
â”‚â”€â”€ src/
â”‚   â”œâ”€â”€ data_pipeline/   # Ingestion & preprocessing scripts
â”‚   â”œâ”€â”€ model/           # Training, evaluation, registry
â”‚   â”œâ”€â”€ logger/          # Logging utilities
â”‚â”€â”€ flask_app/           # Flask web app
â”‚â”€â”€ tests/               # Unit tests
â”‚â”€â”€ .dvc/                # DVC cache & metadata
â”‚â”€â”€ .github/workflows/   # GitHub Actions pipeline
â”‚â”€â”€ requirements.txt     # Optimized dependencies
â”‚â”€â”€ Dockerfile           # Docker configuration
â”‚â”€â”€ dvc.yaml             # DVC pipeline definition
â”‚â”€â”€ .env.example         # Example env file
â”‚â”€â”€ README.md            # Project documentation
```

---

## ğŸš€ Getting Started

### 1ï¸âƒ£ Clone Repository

```bash
git clone https://github.com/<your-username>/MLops_end_to_end.git
cd MLops_end_to_end
```

### 2ï¸âƒ£ Setup Environment

```bash
python -m venv venv
source venv/bin/activate   # Mac/Linux
venv\Scripts\activate      # Windows
pip install -r requirements.txt
```

Create a `.env` file:

```
CAPSTONE_TEST=your_dagshub_token
```

### 3ï¸âƒ£ Run DVC Pipeline

```bash
dvc repro
```

### 4ï¸âƒ£ Run Tests

```bash
pytest tests/
```

### 5ï¸âƒ£ Run Flask App

```bash
python flask_app/app.py
```

or with Docker:

```bash
docker build -t capstone-app:latest .
docker run --env-file .env -p 8888:3000 capstone-app:latest
```

---

## ğŸ”— CI/CD with GitHub Actions

* Workflow runs automatically on every push.
* Steps:

  1. Install dependencies
  2. Run DVC pipeline
  3. Run tests
  4. Log metrics & artifacts to DagsHub MLflow
  5. Promote best model to **Production**

---

## ğŸ“Š Monitoring

* **Prometheus**: Collects request counts, latencies, prediction distribution.
* **Grafana**: Dashboards to visualize model performance in production.
  (Currently configured for local setup, AWS deployment planned later).

---

## ğŸ› ï¸ Tech Stack

* **MLflow** â†’ Experiment tracking & model registry
* **DVC** â†’ Pipeline automation & data versioning
* **AWS S3** â†’ Remote storage for DVC
* **DagsHub** â†’ Remote MLflow tracking
* **Flask** â†’ Model serving API
* **Docker** â†’ Containerization
* **GitHub Actions** â†’ CI/CD automation
* **Prometheus + Grafana** â†’ Monitoring

